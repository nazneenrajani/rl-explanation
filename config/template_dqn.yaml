# Environment settings
env_name: 'MiniGrid-Empty-5x5-v0'
env_wrappers: ['FullyObsWrapper', 'ImageChannelSwapWrapper'] # The first wrapper wraps around the env first
env_wrapper_args: [[], []]

# Randomization
seed: 1

# Discounting
gamma: 0.95

# Exploration with epsilon greedy
eps_start: 1.0
eps_end: 0.1
eps_decay: 20000

# Boltzmann matching policy
temp_start: 1.0
temp_end: 0.1
temp_decay: 20000

# Model
model: MultiHeadDQN
policy: EpsilonGreedyPolicy

# Optimizer
optimizer: RMSprop

# Target network settings
target_update: 4000 # steps

# Number of episodes
num_episodes: 10000

# Evaluation settings
eval_freq: 1000 # steps
eval_eps: 3 # number of evaluation episodes
eval_dir: /export/share/karan-goel/rlexp/

n_attention_heads: 1

# Checkpoint settings
checkpoint_freq: 10000 # steps

# Replay buffer settings
replay_buffer_size: 20000

# Optimization settings
update_freq: 1 # steps
batch_size: 256
lr: 0.0003
dist_lr: 0.0003

# Policy matching loss
matching_loss: kl
matching_loss_coef: 1.0
q_matching: False
q_matching_loss_coef: 1.0

# Deep network settings
conv_layers: [[8, 2, 1], [8, 2, 1]]
output_wts: True
detach_attn_context: True

# Predicates to use
predicates: []
predicate_args: []

# Weights and Biases configuration settings
wandb_org: salesforce
wandb_project: rlexp-v1
wandb_tags: v1

